<h1>The DORA AI Paradox: Schedule &amp; Quick Reference</h1>
<p><strong>Theme</strong>: AI's Productivity Gains vs. Stability Collapse: The Great DORA Paradox</p>
<p><strong>Core Question</strong>: How can we maximize AI's benefits while actively reducing its negative impact on software delivery stability ($\downarrow -7.2%$), by returning to core DORA principles (small batch sizes, user-centricity, stable priorities)?</p>
<h2>Meeting Schedule</h2>
<table class="table">
<thead class="table__head">
<tr class="table__row">
<th class="table__cell table__cell--header">Meeting</th>
<th class="table__cell table__cell--header">Date</th>
<th class="table__cell table__cell--header">Duration</th>
<th class="table__cell table__cell--header">Reading Required (Targeted)</th>
<th class="table__cell table__cell--header">Focus</th>
</tr>
</thead>
<tbody class="table__body">
<tr class="table__row">
<td class="table__cell">Meeting 0: Kickoff</td>
<td class="table__cell">Week 1</td>
<td class="table__cell">30 min</td>
<td class="table__cell">None</td>
<td class="table__cell">Baseline assessment &amp; Current AI reliance</td>
</tr>
<tr class="table__row">
<td class="table__cell">Meeting 1: AI's Dual Impact</td>
<td class="table__cell">Week 3</td>
<td class="table__cell">60 min</td>
<td class="table__cell">Pages 17-26, 27-38</td>
<td class="table__cell">The Paradox: Benefits (Flow, Productivity) vs. The Major Detriment (Stability Drop)</td>
</tr>
<tr class="table__row">
<td class="table__cell">Meeting 2: Solution &amp; Strategy</td>
<td class="table__cell">Week 5</td>
<td class="table__cell">60 min</td>
<td class="table__cell">Pages 57-68, 69-76</td>
<td class="table__cell">The Hypotheses: Batch Size, Vacuum, and the Power of User-Centricity/Stable Priorities</td>
</tr>
<tr class="table__row">
<td class="table__cell">Meeting 3: Lessons</td>
<td class="table__cell">Week 9</td>
<td class="table__cell">30 min</td>
<td class="table__cell">Experiment data</td>
<td class="table__cell">Review experiment results &amp; next steps</td>
</tr>
</tbody>
</table>
<h2>Meeting 0: Baseline Assessment (Week 1)</h2>
<p><strong>Duration</strong>: 30 minutes | <strong>Reading</strong>: None</p>
<h3>Pre-Work (Send 2-3 days before)</h3>
<p>Take 5 minutes to note:</p>
<ul>
<li>One task you used AI for this week (code, writing, summary).</li>
<li>The last major production incident we had and its root cause (1-2 sentences).</li>
<li>How stable do our org priorities feel? (1-5 scale)</li>
</ul>
<h3>Key Questions</h3>
<ul>
<li>What AI tools are we relying on today (and why)?</li>
<li>Where is our greatest current friction point in delivery (the real bottleneck)?</li>
<li>What is the current team-wide consensus on trust in AI-generated code?</li>
</ul>
<p><strong>Immediate Action</strong>: We must define one metric to track AI impact (e.g., PR size, deployment frequency).</p>
<h3>Outcome</h3>
<p>Establish baseline understanding of team's current state with AI and delivery performance.</p>
<h2>Quick Reference: Key Concepts</h2>
<h3>The Vacuum Hypothesis</h3>
<p>AI increases productivity but DECREASES time on valuable work.</p>
<p><strong>Result</strong>: A &quot;vacuum&quot; of time that gets filled with non-valuable work (meetings, interruptions).</p>
<h3>The Stability Contradiction (The Paradox)</h3>
<p><strong>Observed</strong>: Better processes (code quality, documentation, reviews)</p>
<p><strong>Observed</strong>: WORSE delivery stability ($\downarrow -7.2%$)</p>
<p><strong>Leading Hypothesis</strong>: AI enables larger batch sizes (changelists), which DORA consistently shows is the primary driver for low stability.</p>
<h3>User-Centricity</h3>
<p>Four behaviors that define user-centric teams:</p>
<ul>
<li>Incorporate user feedback to reprioritize features.</li>
<li>Know what users want to accomplish.</li>
<li>Believe user experience is key to business success.</li>
<li>Treat user experience as top priority.</li>
</ul>
<p><strong>Insight</strong>: When teams do this well, they can achieve high product quality even without perfect delivery metrics.</p>
<h3>Experiment Template (for Meeting 2)</h3>
<p><strong>EXPERIMENT COMMITMENT</strong></p>
<p><strong>Problem</strong>: [What we're trying to improve, e.g., &quot;The average size of our Pull Requests is increasing.&quot;]</p>
<p><strong>Hypothesis</strong>: If we [action, e.g., &quot;enforce a 100-line limit on AI-generated code snippets in a single PR&quot;], then we expect [outcome, e.g., &quot;our change failure rate to decrease by 5%&quot;].</p>
<p><strong>Measurement</strong>: We'll track [metric] and consider it successful if [criteria].</p>
<p><strong>Duration</strong>: [timeframe - recommend 2-4 weeks]</p>
<p><strong>Owner</strong>: [Who's coordinating this?]</p>
<p><strong>Check-in</strong>: [When will we review progress?]</p>
<h2>Resources</h2>
<p>Full PDF:</p>
<p>$$Link to DORA report$$</p>
<p>DORA Quick Check: https://dora.dev/quickcheck</p>
<p>DORA Capabilities: https://dora.dev/capabilities</p>
<p>Discussion Space:</p>
<p>$$Slack channel / Teams link$$</p>
<h2>Contact</h2>
<p>Facilitator:</p>
<p>$$Your name$$</p>
<p>Questions:</p>
<p>$$Contact method$$</p>
<p>&quot;The best teams are those that achieve elite improvement, not necessarily elite performance.&quot; - DORA Report 2024</p>
