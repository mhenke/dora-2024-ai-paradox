<h1>Meeting 2: Downstream Detriments &amp; Strategy</h1>
<h2>Overview</h2>
<p>This meeting focuses on the downstream detriments of AI adoption, particularly its impact on software delivery stability and throughput. We will explore the leading hypothesis linking AI to larger changelists and lower stability, and discuss the critical roles of user-centricity and stable priorities in mitigating these negative effects. The session will conclude with a commitment to actionable experiments.</p>
<h2>Reading Required</h2>
<p>Pages 57-68, 69-76 of the 2024 DORA Accelerate State of DevOps Report.</p>
<h2>Facilitator Guide Details</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 60 min</p>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Send reading reminder 1 week before (Pgs 57-68, 69-76).</li>
<li>[ ] Prepare Figure 15 (p. 60) from the PDF to share (User-Centricity and Product Performance).</li>
<li>[ ] Prepare Figure 17 (p. 67) from the PDF to share (Priority Stability and Software Delivery Stability).</li>
<li>[ ] Have the Experiment Template ready in a shared, editable document.</li>
</ul>
<h3>Agenda</h3>
<p>Delivery Performance (10 min)</p>
<ul>
<li>Review the observed decline in software delivery stability ($\downarrow -7.2%$) and throughput ($\downarrow -1.5%$) with increased AI adoption (Visual Summary).</li>
<li>Discuss why, historically, better code quality and faster reviews led to better delivery performance, but with AI, this trend is reversed (p. 27).</li>
</ul>
<hr>
<p>The Leading Hypothesis: AI, Changelists, and Stability (15 min)</p>
<ul>
<li>Discuss the hypothesis: AI → Faster code writing → Larger changelists → Lower stability (Visual Summary).</li>
<li>Explore the idea that AI may be causing us to forget DORA's basic principle: Small batch sizes = Fast + Stable.</li>
<li>Are our Pull Requests (PRs) getting bigger with AI assistance? Can we measure this?</li>
</ul>
<hr>
<p>User-Centricity as a Mitigation Strategy (15 min)</p>
<ul>
<li>Discuss DORA's surprising finding: &quot;When organizations focus on the user, stability and throughput of software delivery are not a requirement for product quality.&quot; (p. 59). Product quality will be high as long as the user experience is at the forefront.</li>
<li>Review the four behaviors of user-centric teams (p. 58). Which of these is our greater organizational weakness?</li>
<li>Discuss how user-centered approaches increase productivity, job satisfaction, and reduce burnout (p. 59).</li>
<li>Reference: Visual Summary - &quot;The Alternative Path: User-Centricity&quot; section.</li>
<li>Facilitator Note: Prepare Figure 15 (p. 60) from the PDF to share (Product performance and delivery throughput across 3 levels of user centricity).</li>
</ul>
<hr>
<p>The Priority Stability Problem (10 min)</p>
<ul>
<li>Discuss how unstable organizational priorities lead to meaningful decreases in productivity and substantial increases in burnout (p. 65).</li>
<li>Explore the finding that strong leaders, good documentation, and user-centered approaches <em>cannot</em> mitigate the burnout caused by unstable priorities (p. 65).</li>
<li>How stable are our priorities currently? What can organizations do to stabilize priorities or shield employees from constant shifts? (p. 68).</li>
<li>Reference: Visual Summary - &quot;The Priority Stability Problem&quot; section.</li>
<li>Facilitator Note: Prepare Figure 17 (p. 67) from the PDF to share (Software delivery stability as a function of adding AI-powered experiences).</li>
</ul>
<hr>
<p>Experiment Commitment (10 min)</p>
<ul>
<li>Use the Experiment Template to design a mitigation strategy for the AI Paradox (e.g., limiting PR size, stabilizing a priority).</li>
<li>Define the problem, hypothesis, measurement, duration, owner, and check-in for the experiment.</li>
<li>Reference: Quick Reference - &quot;Experiment Template (for Meeting 2)&quot;.</li>
</ul>
<h3>Key Questions</h3>
<ul>
<li>Are our Pull Requests (PRs) getting bigger with AI assistance? Can we measure this?</li>
<li>How user-centric are we really as a team/organization?</li>
<li>How stable are our organizational priorities currently?</li>
<li>What experiment will we commit to in order to mitigate the AI Paradox or address foundational issues?</li>
</ul>
<h2>Meeting Resources</h2>
<ul>
<li>Deep Dive Podcast: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting2/podcast.mp3</code></li>
<li>PDF Slides: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting2/slides.pdf</code></li>
<li>Video: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting2/video.mp4</code></li>
</ul>
<h3>Facilitator Post Meeting</h3>
<ul>
<li>[ ] Send out meeting summary and the documented experiment commitment.</li>
<li>[ ] Set calendar reminder for check-in/Meeting 3.</li>
<li>[ ] Distribute reading materials for Meeting 3 (Experiment data).</li>
<li>[ ] Schedule Meeting 3.</li>
</ul>
