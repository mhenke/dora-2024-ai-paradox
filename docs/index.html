<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>DORA AI Paradox Book Club</title>
        <link rel="stylesheet" href="style.css" />
    </head>
    <body>
        <div class="container">
            <h1>DORA AI Paradox Book Club</h1>

            <div class="tab">
                <button class="tab__button" type="button" data-tab="overview">
                    Overview
                </button>
                <button class="tab__button" type="button" data-tab="facilitator-guide">
                    Facilitator Guide
                </button>
                <button class="tab__button" type="button" data-tab="visual-summary">Visual Summary</button>
                <button class="tab__button" type="button" data-tab="meeting-0">Meeting 0</button>
                <button class="tab__button" type="button" data-tab="meeting-1">Meeting 1</button>
                <button class="tab__button" type="button" data-tab="meeting-2">Meeting 2</button>
                <button class="tab__button" type="button" data-tab="meeting-3">Meeting 3</button>
            </div>

            <div id="overview" class="tabcontent">
                <h1>The DORA AI Paradox: Schedule &amp; Quick Reference</h1>
<p><strong>Theme</strong>: AI's Productivity Gains vs. Stability Collapse: The Great DORA Paradox</p>
<p><strong>Core Question</strong>: How can we maximize AI's benefits while actively reducing its negative impact on software delivery stability ($\downarrow -7.2%$), by returning to core DORA principles (small batch sizes, user-centricity, stable priorities)?</p>
<h2>Meeting Schedule</h2>
<table>
<thead>
<tr>
<th style="text-align:left">Meeting</th>
<th style="text-align:left">Date</th>
<th style="text-align:left">Duration</th>
<th style="text-align:left">Reading Required (Targeted)</th>
<th style="text-align:left">Focus</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Meeting 0: Kickoff</td>
<td style="text-align:left">Week 1</td>
<td style="text-align:left">30 min</td>
<td style="text-align:left">None</td>
<td style="text-align:left">Baseline assessment &amp; Current AI reliance</td>
</tr>
<tr>
<td style="text-align:left">Meeting 1: AI's Dual Impact</td>
<td style="text-align:left">Week 3</td>
<td style="text-align:left">60 min</td>
<td style="text-align:left">Pages 17-26, 27-38</td>
<td style="text-align:left">The Paradox: Benefits (Flow, Productivity) vs. The Major Detriment (Stability Drop)</td>
</tr>
<tr>
<td style="text-align:left">Meeting 2: Solution &amp; Strategy</td>
<td style="text-align:left">Week 5</td>
<td style="text-align:left">60 min</td>
<td style="text-align:left">Pages 57-68, 69-76</td>
<td style="text-align:left">The Hypotheses: Batch Size, Vacuum, and the Power of User-Centricity/Stable Priorities</td>
</tr>
<tr>
<td style="text-align:left">Meeting 3: Lessons</td>
<td style="text-align:left">Week 9</td>
<td style="text-align:left">30 min</td>
<td style="text-align:left">Experiment data</td>
<td style="text-align:left">Review experiment results &amp; next steps</td>
</tr>
</tbody>
</table>
<h2>Meeting 0: Baseline Assessment (Week 1)</h2>
<p><strong>Duration</strong>: 30 minutes | <strong>Reading</strong>: None</p>
<h3>Pre-Work (Send 2-3 days before)</h3>
<p>Take 5 minutes to note:</p>
<ul>
<li>One task you used AI for this week (code, writing, summary).</li>
<li>The last major production incident we had and its root cause (1-2 sentences).</li>
<li>How stable do our org priorities feel? (1-5 scale)</li>
</ul>
<h3>Key Questions</h3>
<ul>
<li>What AI tools are we relying on today (and why)?</li>
<li>Where is our greatest current friction point in delivery (the real bottleneck)?</li>
<li>What is the current team-wide consensus on trust in AI-generated code?</li>
</ul>
<p><strong>Immediate Action</strong>: We must define one metric to track AI impact (e.g., PR size, deployment frequency).</p>
<h3>Outcome</h3>
<p>Establish baseline understanding of team's current state with AI and delivery performance.</p>
<h2>Quick Reference: Key Concepts</h2>
<h3>The Vacuum Hypothesis</h3>
<p>AI increases productivity but DECREASES time on valuable work.</p>
<p><strong>Result</strong>: A &quot;vacuum&quot; of time that gets filled with non-valuable work (meetings, interruptions).</p>
<h3>The Stability Contradiction (The Paradox)</h3>
<p><strong>Observed</strong>: Better processes (code quality, documentation, reviews)</p>
<p><strong>Observed</strong>: WORSE delivery stability ($\downarrow -7.2%$)</p>
<p><strong>Leading Hypothesis</strong>: AI enables larger batch sizes (changelists), which DORA consistently shows is the primary driver for low stability.</p>
<h3>User-Centricity</h3>
<p>Four behaviors that define user-centric teams:</p>
<ul>
<li>Incorporate user feedback to reprioritize features.</li>
<li>Know what users want to accomplish.</li>
<li>Believe user experience is key to business success.</li>
<li>Treat user experience as top priority.</li>
</ul>
<p><strong>Insight</strong>: When teams do this well, they can achieve high product quality even without perfect delivery metrics.</p>
<h3>Experiment Template (for Meeting 2)</h3>
<p><strong>EXPERIMENT COMMITMENT</strong></p>
<p><strong>Problem</strong>: [What we're trying to improve, e.g., &quot;The average size of our Pull Requests is increasing.&quot;]</p>
<p><strong>Hypothesis</strong>: If we [action, e.g., &quot;enforce a 100-line limit on AI-generated code snippets in a single PR&quot;], then we expect [outcome, e.g., &quot;our change failure rate to decrease by 5%&quot;].</p>
<p><strong>Measurement</strong>: We'll track [metric] and consider it successful if [criteria].</p>
<p><strong>Duration</strong>: [timeframe - recommend 2-4 weeks]</p>
<p><strong>Owner</strong>: [Who's coordinating this?]</p>
<p><strong>Check-in</strong>: [When will we review progress?]</p>
<h2>Resources</h2>
<p>Full PDF:</p>
<p>$$Link to DORA report$$</p>
<p>DORA Quick Check: https://dora.dev/quickcheck</p>
<p>DORA Capabilities: https://dora.dev/capabilities</p>
<p>Discussion Space:</p>
<p>$$Slack channel / Teams link$$</p>
<h2>Contact</h2>
<p>Facilitator:</p>
<p>$$Your name$$</p>
<p>Questions:</p>
<p>$$Contact method$$</p>
<p>&quot;The best teams are those that achieve elite improvement, not necessarily elite performance.&quot; - DORA Report 2024</p>

            </div>

            <div id="facilitator-guide" class="tabcontent">
                <h1>The DORA AI Paradox: Facilitator Guide</h1>
<p><strong>Duration</strong>: 6 weeks total (3 meetings + 1 checkpoint)
<strong>Meeting Frequency</strong>: Every 2 weeks
<strong>Format</strong>: 60-minute discussions</p>
<h2>Overall Theme &amp; Learning Objectives</h2>
<p><strong>Core Tension</strong>: AI's immediate benefits versus its complex downstream consequences.</p>
<p><strong>Guiding Question</strong>: How can we maximize the organizational and individual benefits of AI adoption while proactively managing the unexpected trade-offs, particularly the $\downarrow -7.2%$ drop in software delivery stability?</p>
<h3>Learning Objectives:</h3>
<ul>
<li>Establish baseline understanding of current AI usage and delivery friction.</li>
<li>Critically analyze the AI Paradox: improved processes leading to worse outcomes.</li>
<li>Identify and test the core drivers: Batch Size and Stable Priorities.</li>
<li>Commit to actionable experiments using DORA's continuous improvement framework.</li>
</ul>
<h2>Timeline Overview</h2>
<table>
<thead>
<tr>
<th style="text-align:left">Week</th>
<th style="text-align:left">Activity</th>
<th style="text-align:left">Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Week 0</td>
<td style="text-align:left">Kickoff invite + Pre-meeting reflection</td>
<td style="text-align:left">5 min homework</td>
</tr>
<tr>
<td style="text-align:left">Week 1</td>
<td style="text-align:left">Meeting 0: Baseline Assessment</td>
<td style="text-align:left">30 min</td>
</tr>
<tr>
<td style="text-align:left">Week 2-3</td>
<td style="text-align:left">Reading for Meeting 1</td>
<td style="text-align:left">Self-paced</td>
</tr>
<tr>
<td style="text-align:left">Week 3</td>
<td style="text-align:left">Meeting 1: AI's Benefits &amp; the Individual Paradox</td>
<td style="text-align:left">60 min</td>
</tr>
<tr>
<td style="text-align:left">Week 4-5</td>
<td style="text-align:left">Reading for Meeting 2</td>
<td style="text-align:left">Self-paced</td>
</tr>
<tr>
<td style="text-align:left">Week 5</td>
<td style="text-align:left">Meeting 2: Downstream Detriments &amp; Strategy</td>
<td style="text-align:left">60 min</td>
</tr>
<tr>
<td style="text-align:left">Week 5-9</td>
<td style="text-align:left">Team experiments in action</td>
<td style="text-align:left">Ongoing</td>
</tr>
<tr>
<td style="text-align:left">Week 9</td>
<td style="text-align:left">Meeting 3: Lessons from Experiments (Optional)</td>
<td style="text-align:left">30 min</td>
</tr>
</tbody>
</table>
<h2>Meeting 0: Baseline Assessment &amp; Kickoff</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 30 min</p>
<h3>Discussion Flow</h3>
<ul>
<li><strong>Introduction (5 min)</strong>: Set the context—this is about critical analysis, not praise. The report identified major trade-offs.</li>
<li><strong>Pre-Work Review (15 min)</strong>: Capture collective answers on the whiteboard. Focus on question #2: Where is the greatest current friction in delivery?</li>
<li><strong>Core Metric Definition (10 min)</strong>: As a team, decide on one quantitative metric (e.g., Change Failure Rate or PR Size) that the group will track over the course of the book club.</li>
</ul>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Ensure the 4 key questions are visible.</li>
<li>[ ] Prepare reading assignment handout (Pgs 17-38).</li>
</ul>
<h2>Meeting 1: AI's Benefits &amp; the Individual Paradox</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 60 min</p>
<h3>Discussion Flow</h3>
<ul>
<li><strong>Review Benefits (15 min)</strong>: Discuss individual gains (flow, productivity) and process improvements (code quality, docs).</li>
<li><strong>The Vacuum Hypothesis (20 min)</strong>: Discuss the $\downarrow -2.6%$ time on valuable work drop. Where is this time going locally? (Use the diagram from the Visual Summary).</li>
<li><strong>The Stability Contradiction (25 min)</strong>: Introduce the major finding: Stability $\downarrow -7.2%$. Why would faster reviews and better code quality lead to worse outcomes? This should be the most contentious part of the meeting.</li>
</ul>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Send reading reminder 1 week before with page numbers.</li>
<li>[ ] Have whiteboard ready for the Vacuum Hypothesis diagram (from the Visual Summary).</li>
<li>[ ] Prepare Figure 7 (p. 32) from the PDF to share (Impact on Delivery Metrics).</li>
</ul>
<h2>Meeting 2: Downstream Detriments &amp; Strategy</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 60 min</p>
<h3>Discussion Flow</h3>
<ul>
<li><strong>Batch Size Check (15 min)</strong>: Discuss the Leading Hypothesis (AI $\to$ Larger Changelists $\to$ Lower Stability). Are our PRs getting bigger? Use the Batch Size diagram from the Visual Summary.</li>
<li><strong>User-Centricity/Stable Priorities (25 min)</strong>: Discuss the two key non-AI differentiators. Which of these is our greater organizational weakness? (Refer to the Four behaviors that define user-centric teams from the Quick Reference).</li>
<li><strong>Experiment Commitment (20 min)</strong>: Use the Experiment Template. The experiment must be designed to test a mitigation strategy for the AI Paradox (e.g., limit PR size) or one of the foundational issues (e.g., stabilize a priority).</li>
</ul>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Send reading reminder 1 week before (Pgs 57-68, 69-76).</li>
<li>[ ] Prepare Figure 15 (p. 60) and Figure 17 (p. 67) from the PDF to share (User-Centricity and Priority Stability).</li>
<li>[ ] Have the Experiment Template ready in a shared, editable document.</li>
</ul>
<h2>Recommended Follow-Up Actions</h2>
<p><strong>After Meeting 2:</strong></p>
<ul>
<li><strong>MANDATORY</strong>: Document the experiment commitment clearly, including the specific DORA metric being tracked.</li>
<li>Set calendar reminder for check-in/Meeting 3.</li>
<li>Begin tracking agreed-upon metrics (e.g., average PR size, change failure rate).</li>
</ul>

            </div>

            <div id="visual-summary" class="tabcontent">
                <h1>The AI Paradox: Visual Summary</h1>
<p>From the 2024 DORA Accelerate State of DevOps Report</p>
<h2>The Central Tension</h2>
<p>AI ADOPTION CREATES TWO OPPOSING FORCES:</p>
<p>✓ CLEAR BENEFITS              vs.        ⚠ UNEXPECTED CONSEQUENCES
(Individual &amp; Process Level)              (Delivery &amp; Stability Level: ↓ 7.2%)</p>
<h2>What's Working: The Benefits</h2>
<h3>Individual Level (per 25% increase in AI adoption)</h3>
<p>Productivity        ↑ +2.1%
Flow state          ↑ +2.6%
Job satisfaction    ↑ +2.2%</p>
<p>BUT: Time on valuable work ↓ −2.6%  ⚠</p>
<h3>Process Level</h3>
<p>Code quality           ↑ +3.4%
Documentation quality  ↑ +7.5%
Code review speed      ↑ +3.1%
Approval speed         ↑ +1.3%
Code complexity        ↓ −1.8%</p>
<h3>Team &amp; Organization Level</h3>
<p>Team performance           ↑ +1.4%
Organizational performance ↑ +2.3%
Product performance        → +0.2% (minimal change)</p>
<h2>What's Broken: The Contradiction</h2>
<h3>Delivery Performance (per 25% increase in AI adoption)</h3>
<p>⚠ Software delivery stability  ↓ −7.2%  (MAJOR DECLINE)
⚠ Software delivery throughput ↓ −1.5%  (minor decline)</p>
<h3>The Paradox:</h3>
<p>Historically, better code quality + faster reviews = better delivery performance</p>
<p>With AI: Better processes → WORSE delivery stability</p>
<p>This shouldn't happen!</p>
<h3>The Leading Hypothesis</h3>
<p>AI → Faster code writing → Larger changelists → Lower stability</p>
<p>DORA's Basic Principle: Small batch sizes = Fast + Stable
AI may be causing us to forget this principle</p>
<h3>The Vacuum Hypothesis</h3>
<p>Why does AI increase productivity but DECREASE time on valuable work?</p>
<p>BEFORE AI:
[████████ Valuable Work: 60%] [█████ Toil: 40%]</p>
<p>AFTER AI:
[███████ Valuable Work: 57%] [█████ Toil: 40%] [? Mystery: 3%]</p>
<p>Theory: AI helps us finish valuable work FASTER, creating a time vacuum.
That vacuum gets filled with... meetings, interruptions, context switching.
AI doesn't reduce TOIL (meetings, bureaucracy) - it just speeds up the good stuff.</p>
<h3>The Trust Paradox</h3>
<p>39.2% of developers report little or no trust in AI-generated code</p>
<p>YET</p>
<p>75.9% rely on AI for at least one task</p>
<p>Why? Low trust doesn't stop usage - people just verify and modify the output.
&quot;Mostly correct&quot; code that needs tweaking is valuable enough to use.</p>
<h3>The Alternative Path: User-Centricity</h3>
<p>DORA's Surprising Finding:</p>
<p>&quot;When organizations focus on the user, stability and throughput of software
delivery are not a requirement for product quality.&quot; (p. 59)</p>
<p>Traditional Path to Success:
Fast delivery + Stable delivery = High-performing product</p>
<p>Alternative Path to Success:
Deep user understanding = High-performing product
(even with imperfect delivery metrics)</p>
<h3>Four behaviors of user-centric teams:</h3>
<p>✓ Incorporate user feedback to reprioritize features</p>
<p>✓ Know what users want to accomplish</p>
<p>✓ Believe user experience is key to business success</p>
<p>✓ Treat user experience as top priority</p>
<h3>The Priority Stability Problem</h3>
<p>Unstable organizational priorities lead to:
• Meaningful DECREASE in productivity
• Substantial INCREASE in burnout</p>
<p>This effect persists even with:
✓ Strong transformational leadership
✓ High-quality internal documentation
✓ User-centric approach</p>
<p>Fix: Stabilize priorities (easier said than done)</p>
<h2>AI Adoption Statistics</h2>
<h3>Organizations:</h3>
<p>• 81% have shifted priorities to increase AI incorporation
• AI prioritization varies by org size (smaller = faster adoption)
• No meaningful difference by industry vertical</p>
<h3>Individuals:</h3>
<p>• 75.9% rely on AI for at least one task
• Top uses: Writing code (74.9%), Summarizing info (71.2%)
• 75% report positive productivity gains
• 39.2% report little/no trust in AI code quality</p>
<h2>The Future Outlook: Mixed Feelings</h2>
<p>Respondents expect AI will have POSITIVE impact on:</p>
<p>Product quality (in 1, 5, and 10 years)</p>
<p>Respondents expect AI will have NEGATIVE impact on:</p>
<p>Their own careers (peaks at 5 years)</p>
<p>Society as a whole (peaks at 5 years)</p>
<p>The environment (peaks at 5 years)</p>
<p>The Disconnect: Short-term experience is positive, but long-term expectations are pessimistic.</p>
<h2>The DORA Continuous Improvement Cycle</h2>
<ol>
<li>Identify area to improve
↓</li>
<li>Measure baseline
↓</li>
<li>Develop hypotheses
↓</li>
<li>Commit to a plan  ← OUR BOOK CLUB ENDS HERE
↓</li>
<li>Do the work
↓</li>
<li>Measure progress
↓</li>
<li>REPEAT ↻</li>
</ol>
<p>Key Insight: &quot;The best teams are those that achieve elite improvement,
not necessarily elite performance.&quot;</p>
<h2>Key Questions for Discussion</h2>
<h3>Meeting 1: Benefits &amp; Paradox</h3>
<p>Where does the AI-freed time actually go?</p>
<p>Is code quality truly better, or just easier to work with?</p>
<p>Why the disconnect between current gains and future pessimism?</p>
<h3>Meeting 2: Detriments &amp; Strategy</h3>
<p>Are our batch sizes increasing with AI?</p>
<p>Can we measure this?</p>
<p>How user-centric are we really?</p>
<p>How stable are our priorities?</p>
<p>What experiment will we commit to?</p>
<h2>The Bottom Line</h2>
<p>AI IS TRANSFORMATIVE, BUT COMPLEX:</p>
<p>✓ Individuals feel more productive, satisfied, and in flow
✓ Code quality, documentation, and reviews improve
⚠ But delivery stability takes a significant hit
⚠ And valuable work time mysteriously decreases</p>
<p>THE CHALLENGE:
Maximize benefits while managing trade-offs through:
• Small batch sizes (DORA's core principle)
• User-centricity (alternative path to quality)
• Stable priorities (foundation for well-being)
• Continuous improvement (the only path forward)</p>
<p>Source: 2024 DORA Accelerate State of DevOps Report
Available at: https://dora.dev/research/2024/dora-report/</p>

            </div>

            <div id="meeting-0" class="tabcontent">
                <h1>Meeting 0: Baseline Assessment &amp; Kickoff</h1>
<h2>Overview</h2>
<p>This kickoff meeting aims to establish a baseline understanding of the team's current AI usage, perceptions, and existing delivery friction. We will define a core metric to track AI's impact throughout the book club series.</p>
<h2>Reading Required</h2>
<p>None</p>
<h2>Facilitator Guide Details</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 30 min</p>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Ensure the key questions are visible (e.g., on a whiteboard or shared document).</li>
<li>[ ] Prepare reading assignment handout for Meeting 1 (Pages 17-38 of the DORA report).</li>
</ul>
<h3>Agenda</h3>
<p>Introduction &amp; Context (5 min)</p>
<ul>
<li>Set the context—this book club is about critical analysis of AI's impact, not just praise. The DORA report identified major trade-offs that we will explore.</li>
</ul>
<hr>
<p>Review Pre-Work &amp; Current Friction Points (15 min)</p>
<ul>
<li>Capture collective answers on the whiteboard regarding individual AI usage, recent production incidents, and perceived organizational priority stability. Focus discussion on identifying the greatest current friction point in delivery.</li>
</ul>
<hr>
<p>Define Core Metric for Tracking AI Impact (10 min)</p>
<ul>
<li>As a team, decide on one quantitative metric (e.g., Change Failure Rate, PR Size, Deployment Frequency) that the group will track over the course of the book club to measure AI's impact.</li>
</ul>
<h3>Key Questions</h3>
<ul>
<li>What AI tools are we relying on today (and why)?</li>
<li>Where is our greatest current friction point in delivery (the real bottleneck)?</li>
<li>What is the current team-wide consensus on trust in AI-generated code?</li>
<li>How stable do our organizational priorities feel? (1-5 scale)</li>
</ul>
<h2>Meeting Resources</h2>
<ul>
<li>Deep Dive Podcast: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting0/podcast.mp3</code></li>
<li>PDF Slides: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting0/slides.pdf</code></li>
<li>Video: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting0/video.mp4</code></li>
</ul>
<h3>Facilitator Post Meeting</h3>
<ul>
<li>[ ] Send out meeting summary and agreed-upon core metric.</li>
<li>[ ] Distribute reading materials for Meeting 1 (Pages 17-38 of the DORA report).</li>
<li>[ ] Schedule Meeting 1.</li>
</ul>
<p>&lt;- ❌ Need hard reboot to TEST CHANGE 1762546889 --&gt;</p>

            </div>

            <div id="meeting-1" class="tabcontent">
                <h1>Meeting 1: AI's Benefits &amp; the Individual Paradox</h1>
<h2>Overview</h2>
<p>This meeting will delve into the dual impact of AI, exploring both the significant benefits it brings to individual productivity and development processes, as well as the surprising detriment to overall software delivery stability. We will critically analyze the &quot;AI Paradox&quot; and the underlying hypotheses.</p>
<h2>Reading Required</h2>
<p>Pages 17-26, 27-38 of the 2024 DORA Accelerate State of DevOps Report.</p>
<h2>Facilitator Guide Details</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 60 min</p>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Send reading reminder 1 week before with page numbers (17-26, 27-38).</li>
<li>[ ] Have whiteboard ready for the Vacuum Hypothesis diagram (from the Visual Summary or Figure 8, p. 35).</li>
<li>[ ] Prepare Figure 7 (p. 32) from the PDF to share (Impacts of AI adoption on individual success and well-being).</li>
<li>[ ] Prepare Figure 9 (p. 37) from the PDF to share (Impacts of AI adoption on organizations).</li>
<li>[ ] Prepare Figure 5 (p. 23) from the PDF to share (Trust in quality of AI-generated code).</li>
<li>[ ] Prepare Figure 6 (p. 25) from the PDF to share (Respondents’ expectations about AI’s future negative impacts).</li>
</ul>
<h3>Agenda</h3>
<p>Review Benefits (15 min)</p>
<ul>
<li><strong>Individual Gains:</strong> Discuss how 75% of respondents reported positive productivity gains from AI. Explore increases in flow state (+2.6%), job satisfaction (+2.2%), and productivity (+2.1%) with a 25% increase in AI adoption (Figure 7, p. 32).</li>
<li><strong>Process Improvements:</strong> Examine how AI adoption is associated with significant improvements in documentation quality (+7.5%), code quality (+3.4%), code review speed (+3.1%), approval speed (+1.3%), and a decrease in code complexity (-1.8%) (Figure 9, p. 37).</li>
<li>Reference: Visual Summary - &quot;What's Working: The Benefits&quot; section.</li>
</ul>
<hr>
<p>The Vacuum Hypothesis (20 min)</p>
<ul>
<li>Discuss the observed $\downarrow -2.6%$ drop in time spent on valuable work despite increased productivity.</li>
<li>Explore the &quot;vacuum hypothesis&quot;: AI helps finish valuable work faster, creating extra time that gets filled with non-valuable work (meetings, interruptions, context switching), rather than reducing toil (p. 33-35).</li>
<li>Reference: Visual Summary - &quot;The Vacuum Hypothesis&quot; diagram and explanation.</li>
</ul>
<hr>
<p>The Stability Contradiction (15 min)</p>
<ul>
<li>Introduce the major finding: Despite process improvements, software delivery stability $\downarrow -7.2%$ (Visual Summary).</li>
<li>Discuss the paradox: Why would better code quality and faster reviews lead to worse outcomes? Is it due to over-reliance on AI or trusting AI-generated code too much? (p. 38).</li>
<li>Reference: Visual Summary - &quot;What's Broken: The Contradiction&quot; section.</li>
</ul>
<hr>
<p>Trust in AI-Generated Code (5 min)</p>
<ul>
<li>Discuss the complex perceptions: 87.9% reported some trust, but 39.2% reported little or no trust (Figure 5, p. 23).</li>
<li>Explore the hypothesis that developers don't require absolute trust; &quot;mostly-correct&quot; AI-generated code that can be tweaked is valuable enough (p. 24).</li>
<li>How does our team verify and modify AI-generated output?</li>
<li>Reference: Visual Summary - &quot;The Trust Paradox&quot; section.</li>
</ul>
<hr>
<p>Expectations for AI's Future (5 min)</p>
<ul>
<li>Discuss the mixed feelings: optimistic about product quality, but pessimistic about careers, society, and the environment in the long term (Figure 6, p. 25).</li>
<li>Reference: Visual Summary - &quot;The Future Outlook: Mixed Feelings&quot; section.</li>
</ul>
<h3>Key Questions</h3>
<ul>
<li>Where does the AI-freed time actually go in our team/organization?</li>
<li>Is code quality truly better, or just easier to work with due to AI assistance?</li>
<li>Why is there a disconnect between current positive gains from AI and future pessimistic expectations?</li>
<li>How does our team currently verify and modify AI-generated output?</li>
</ul>
<h2>Meeting Resources</h2>
<ul>
<li>Deep Dive Podcast: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting1/podcast.mp3</code></li>
<li>PDF Slides: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting1/slides.pdf</code></li>
<li>Video: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting1/video.mp4</code></li>
</ul>
<h3>Facilitator Post Meeting</h3>
<ul>
<li>[ ] Send out meeting summary and any team-specific insights or questions that arose during the discussion.</li>
<li>[ ] Distribute reading materials for Meeting 2 (Pages 57-68, 69-76 of the DORA report).</li>
<li>[ ] Schedule Meeting 2.</li>
</ul>

            </div>

            <div id="meeting-2" class="tabcontent">
                <h1>Meeting 2: Downstream Detriments &amp; Strategy</h1>
<h2>Overview</h2>
<p>This meeting focuses on the downstream detriments of AI adoption, particularly its impact on software delivery stability and throughput. We will explore the leading hypothesis linking AI to larger changelists and lower stability, and discuss the critical roles of user-centricity and stable priorities in mitigating these negative effects. The session will conclude with a commitment to actionable experiments.</p>
<h2>Reading Required</h2>
<p>Pages 57-68, 69-76 of the 2024 DORA Accelerate State of DevOps Report.</p>
<h2>Facilitator Guide Details</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 60 min</p>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Send reading reminder 1 week before (Pgs 57-68, 69-76).</li>
<li>[ ] Prepare Figure 15 (p. 60) from the PDF to share (User-Centricity and Product Performance).</li>
<li>[ ] Prepare Figure 17 (p. 67) from the PDF to share (Priority Stability and Software Delivery Stability).</li>
<li>[ ] Have the Experiment Template ready in a shared, editable document.</li>
</ul>
<h3>Agenda</h3>
<p>Delivery Performance (10 min)</p>
<ul>
<li>Review the observed decline in software delivery stability ($\downarrow -7.2%$) and throughput ($\downarrow -1.5%$) with increased AI adoption (Visual Summary).</li>
<li>Discuss why, historically, better code quality and faster reviews led to better delivery performance, but with AI, this trend is reversed (p. 27).</li>
</ul>
<hr>
<p>The Leading Hypothesis: AI, Changelists, and Stability (15 min)</p>
<ul>
<li>Discuss the hypothesis: AI → Faster code writing → Larger changelists → Lower stability (Visual Summary).</li>
<li>Explore the idea that AI may be causing us to forget DORA's basic principle: Small batch sizes = Fast + Stable.</li>
<li>Are our Pull Requests (PRs) getting bigger with AI assistance? Can we measure this?</li>
</ul>
<hr>
<p>User-Centricity as a Mitigation Strategy (15 min)</p>
<ul>
<li>Discuss DORA's surprising finding: &quot;When organizations focus on the user, stability and throughput of software delivery are not a requirement for product quality.&quot; (p. 59). Product quality will be high as long as the user experience is at the forefront.</li>
<li>Review the four behaviors of user-centric teams (p. 58). Which of these is our greater organizational weakness?</li>
<li>Discuss how user-centered approaches increase productivity, job satisfaction, and reduce burnout (p. 59).</li>
<li>Reference: Visual Summary - &quot;The Alternative Path: User-Centricity&quot; section.</li>
<li>Facilitator Note: Prepare Figure 15 (p. 60) from the PDF to share (Product performance and delivery throughput across 3 levels of user centricity).</li>
</ul>
<hr>
<p>The Priority Stability Problem (10 min)</p>
<ul>
<li>Discuss how unstable organizational priorities lead to meaningful decreases in productivity and substantial increases in burnout (p. 65).</li>
<li>Explore the finding that strong leaders, good documentation, and user-centered approaches <em>cannot</em> mitigate the burnout caused by unstable priorities (p. 65).</li>
<li>How stable are our priorities currently? What can organizations do to stabilize priorities or shield employees from constant shifts? (p. 68).</li>
<li>Reference: Visual Summary - &quot;The Priority Stability Problem&quot; section.</li>
<li>Facilitator Note: Prepare Figure 17 (p. 67) from the PDF to share (Software delivery stability as a function of adding AI-powered experiences).</li>
</ul>
<hr>
<p>Experiment Commitment (10 min)</p>
<ul>
<li>Use the Experiment Template to design a mitigation strategy for the AI Paradox (e.g., limiting PR size, stabilizing a priority).</li>
<li>Define the problem, hypothesis, measurement, duration, owner, and check-in for the experiment.</li>
<li>Reference: Quick Reference - &quot;Experiment Template (for Meeting 2)&quot;.</li>
</ul>
<h3>Key Questions</h3>
<ul>
<li>Are our Pull Requests (PRs) getting bigger with AI assistance? Can we measure this?</li>
<li>How user-centric are we really as a team/organization?</li>
<li>How stable are our organizational priorities currently?</li>
<li>What experiment will we commit to in order to mitigate the AI Paradox or address foundational issues?</li>
</ul>
<h2>Meeting Resources</h2>
<ul>
<li>Deep Dive Podcast: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting2/podcast.mp3</code></li>
<li>PDF Slides: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting2/slides.pdf</code></li>
<li>Video: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting2/video.mp4</code></li>
</ul>
<h3>Facilitator Post Meeting</h3>
<ul>
<li>[ ] Send out meeting summary and the documented experiment commitment.</li>
<li>[ ] Set calendar reminder for check-in/Meeting 3.</li>
<li>[ ] Distribute reading materials for Meeting 3 (Experiment data).</li>
<li>[ ] Schedule Meeting 3.</li>
</ul>

            </div>

            <div id="meeting-3" class="tabcontent">
                <h1>Meeting 3: Lessons from Experiments</h1>
<h2>Overview</h2>
<p>This meeting is dedicated to reviewing the results of the experiments committed to in Meeting 2. We will discuss findings, identify key lessons learned, and determine next steps for continuous improvement based on the DORA metrics.</p>
<h2>Reading Required</h2>
<p>Experiment data (from the team's tracking of the agreed-upon metric).</p>
<h2>Facilitator Guide Details</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 30 min</p>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Ensure experiment data is collected, visualized, and ready for presentation.</li>
<li>[ ] Prepare a template for documenting lessons learned and next steps.</li>
<li>[ ] Be ready to guide the team in proposing new experiments.</li>
</ul>
<h3>Agenda</h3>
<p>Review Experiment Results (15 min)</p>
<ul>
<li>Present the data collected from the experiment (e.g., changes in PR size, change failure rate, deployment frequency). Discuss whether the hypothesis was supported or refuted.</li>
</ul>
<hr>
<p>Discuss Lessons Learned (10 min)</p>
<ul>
<li>Facilitate a discussion on what the team has learned about the AI Paradox, the effectiveness of the mitigation strategy, and the impact on team dynamics or delivery performance.</li>
</ul>
<hr>
<p>Determine Next Steps &amp; Future Experiments (5 min)</p>
<ul>
<li>Based on the lessons learned, decide on concrete next steps. This could include continuing the current experiment, modifying it, or proposing new experiments to further address the AI Paradox or other identified friction points.</li>
</ul>
<h3>Key Questions</h3>
<ul>
<li>What were the results of our experiment? Did we observe the expected outcome?</li>
<li>What key lessons can we draw from these results regarding AI's impact and our mitigation strategies?</li>
<li>What are the recommended next steps for our team based on these findings?</li>
<li>What new experiments should we consider for continuous improvement?</li>
</ul>
<h2>Meeting Resources</h2>
<ul>
<li>Deep Dive Podcast: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting3/podcast.mp3</code></li>
<li>PDF Slides: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting3/slides.pdf</code></li>
<li>Video: <code>https://your-unique-bucket-name.s3.your-aws-region.amazonaws.com/meeting3/video.mp4</code></li>
</ul>
<h3>Facilitator Post Meeting</h3>
<ul>
<li>[ ] Send out meeting summary and the documented lessons learned and any new experiment commitments.</li>
<li>[ ] Communicate findings and next steps to relevant stakeholders.</li>
<li>[ ] Continue tracking agreed-upon metrics for ongoing monitoring.</li>
</ul>

            </div>

            <script src="main.js"></script>
        </div>
    </body>
</html>