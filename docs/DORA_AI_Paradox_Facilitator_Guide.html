<h1>The DORA AI Paradox: Facilitator Guide</h1>
<p><strong>Duration</strong>: 6 weeks total (3 meetings + 1 checkpoint)
<strong>Meeting Frequency</strong>: Every 2 weeks
<strong>Format</strong>: 60-minute discussions</p>
<h2>Overall Theme &amp; Learning Objectives</h2>
<p><strong>Core Tension</strong>: AI's immediate benefits versus its complex downstream consequences.</p>
<p><strong>Guiding Question</strong>: How can we maximize the organizational and individual benefits of AI adoption while proactively managing the unexpected trade-offs, particularly the $\downarrow -7.2%$ drop in software delivery stability?</p>
<h3>Learning Objectives:</h3>
<ul>
<li>Establish baseline understanding of current AI usage and delivery friction.</li>
<li>Critically analyze the AI Paradox: improved processes leading to worse outcomes.</li>
<li>Identify and test the core drivers: Batch Size and Stable Priorities.</li>
<li>Commit to actionable experiments using DORA's continuous improvement framework.</li>
</ul>
<h2>Timeline Overview</h2>
<table>
<thead>
<tr>
<th style="text-align:left">Week</th>
<th style="text-align:left">Activity</th>
<th style="text-align:left">Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Week 0</td>
<td style="text-align:left">Kickoff invite + Pre-meeting reflection</td>
<td style="text-align:left">5 min homework</td>
</tr>
<tr>
<td style="text-align:left">Week 1</td>
<td style="text-align:left">Meeting 0: Baseline Assessment</td>
<td style="text-align:left">30 min</td>
</tr>
<tr>
<td style="text-align:left">Week 2-3</td>
<td style="text-align:left">Reading for Meeting 1</td>
<td style="text-align:left">Self-paced</td>
</tr>
<tr>
<td style="text-align:left">Week 3</td>
<td style="text-align:left">Meeting 1: AI's Benefits &amp; the Individual Paradox</td>
<td style="text-align:left">60 min</td>
</tr>
<tr>
<td style="text-align:left">Week 4-5</td>
<td style="text-align:left">Reading for Meeting 2</td>
<td style="text-align:left">Self-paced</td>
</tr>
<tr>
<td style="text-align:left">Week 5</td>
<td style="text-align:left">Meeting 2: Downstream Detriments &amp; Strategy</td>
<td style="text-align:left">60 min</td>
</tr>
<tr>
<td style="text-align:left">Week 5-9</td>
<td style="text-align:left">Team experiments in action</td>
<td style="text-align:left">Ongoing</td>
</tr>
<tr>
<td style="text-align:left">Week 9</td>
<td style="text-align:left">Meeting 3: Lessons from Experiments (Optional)</td>
<td style="text-align:left">30 min</td>
</tr>
</tbody>
</table>
<h2>Meeting 0: Baseline Assessment &amp; Kickoff</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 30 min</p>
<h3>Discussion Flow</h3>
<ul>
<li><strong>Introduction (5 min)</strong>: Set the contextâ€”this is about critical analysis, not praise. The report identified major trade-offs.</li>
<li><strong>Pre-Work Review (15 min)</strong>: Capture collective answers on the whiteboard. Focus on question #2: Where is the greatest current friction in delivery?</li>
<li><strong>Core Metric Definition (10 min)</strong>: As a team, decide on one quantitative metric (e.g., Change Failure Rate or PR Size) that the group will track over the course of the book club.</li>
</ul>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Ensure the 4 key questions are visible.</li>
<li>[ ] Prepare reading assignment handout (Pgs 17-38).</li>
</ul>
<h2>Meeting 1: AI's Benefits &amp; the Individual Paradox</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 60 min</p>
<h3>Discussion Flow</h3>
<ul>
<li><strong>Review Benefits (15 min)</strong>: Discuss individual gains (flow, productivity) and process improvements (code quality, docs).</li>
<li><strong>The Vacuum Hypothesis (20 min)</strong>: Discuss the $\downarrow -2.6%$ time on valuable work drop. Where is this time going locally? (Use the diagram from the Visual Summary).</li>
<li><strong>The Stability Contradiction (25 min)</strong>: Introduce the major finding: Stability $\downarrow -7.2%$. Why would faster reviews and better code quality lead to worse outcomes? This should be the most contentious part of the meeting.</li>
</ul>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Send reading reminder 1 week before with page numbers.</li>
<li>[ ] Have whiteboard ready for the Vacuum Hypothesis diagram (from the Visual Summary).</li>
<li>[ ] Prepare Figure 7 (p. 32) from the PDF to share (Impact on Delivery Metrics).</li>
</ul>
<h2>Meeting 2: Downstream Detriments &amp; Strategy</h2>
<p><strong>Date</strong>: [Date] | <strong>Duration</strong>: 60 min</p>
<h3>Discussion Flow</h3>
<ul>
<li><strong>Batch Size Check (15 min)</strong>: Discuss the Leading Hypothesis (AI $\to$ Larger Changelists $\to$ Lower Stability). Are our PRs getting bigger? Use the Batch Size diagram from the Visual Summary.</li>
<li><strong>User-Centricity/Stable Priorities (25 min)</strong>: Discuss the two key non-AI differentiators. Which of these is our greater organizational weakness? (Refer to the Four behaviors that define user-centric teams from the Quick Reference).</li>
<li><strong>Experiment Commitment (20 min)</strong>: Use the Experiment Template. The experiment must be designed to test a mitigation strategy for the AI Paradox (e.g., limit PR size) or one of the foundational issues (e.g., stabilize a priority).</li>
</ul>
<h3>Facilitator Preparation</h3>
<ul>
<li>[ ] Send reading reminder 1 week before (Pgs 57-68, 69-76).</li>
<li>[ ] Prepare Figure 15 (p. 60) and Figure 17 (p. 67) from the PDF to share (User-Centricity and Priority Stability).</li>
<li>[ ] Have the Experiment Template ready in a shared, editable document.</li>
</ul>
<h2>Recommended Follow-Up Actions</h2>
<p><strong>After Meeting 2:</strong></p>
<ul>
<li><strong>MANDATORY</strong>: Document the experiment commitment clearly, including the specific DORA metric being tracked.</li>
<li>Set calendar reminder for check-in/Meeting 3.</li>
<li>Begin tracking agreed-upon metrics (e.g., average PR size, change failure rate).</li>
</ul>
